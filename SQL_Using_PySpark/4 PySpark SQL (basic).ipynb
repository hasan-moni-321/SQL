{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"PySpark SQL From SQL ZOO\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing File Type and path for data train\n",
    "file_type = 'text'\n",
    "delimeter=','\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_type):\n",
    "    \"\"\"input type of file \"text\" or \"parquet\" and Return pyspark dataframe\"\"\"\n",
    "    if file_type ==\"text\": # use text as file type input\n",
    "        df = spark.read.option(\"header\", \"true\") \\\n",
    "                       .option(\"delimeter\",delimeter)\\\n",
    "                       .option(\"inferSchema\", \"true\") \\\n",
    "                       .csv(path)  #path file that you want import\n",
    "    else:  \n",
    "        df= spark.read.parquet(\"example.parquet\") #path file that you want import\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading worker dataset\n",
    "path=r'/home/hasan/DATA SET/PySpark SQL/Student.csv'\n",
    "student = load_data(file_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+----------+\n",
      "| ID|FirstName|LastName|   Address|\n",
      "+---+---------+--------+----------+\n",
      "| 34|      Joe|   Kidde| Amsterdam|\n",
      "| 14|     Bide|     Tom|Kelifornia|\n",
      "|  4|     Jack|      Ma|  Oklahoma|\n",
      "| 24|     Dibb|    Dull|  New York|\n",
      "| 54|      Bob|    Kent|Kelifornia|\n",
      "| 44|     Hash|   Kient| Manhattan|\n",
      "| 74|     Joie|    Anti|New Jersey|\n",
      "| 84|    Biden|  Dirich|    Alaska|\n",
      "|  4|    Krish|     Roy|Birmingham|\n",
      "| 94|     Rock| Johnson|    London|\n",
      "|104|     John|     Die|    8Dhaka|\n",
      "+---+---------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- FirstName: string (nullable = true)\n",
      " |-- LastName: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Dataset to SQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "student.createOrReplaceTempView(\"student_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Question and Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q1: Write an sql query to show database\n",
    "spark.sql(\" show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+-----------+\n",
      "|database|   tableName|isTemporary|\n",
      "+--------+------------+-----------+\n",
      "|        |student_data|       true|\n",
      "+--------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q2: Write an sql query to show tables\n",
    "spark.sql(\" show tables \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| ID|LastName|\n",
      "+---+--------+\n",
      "| 34|   Kidde|\n",
      "| 14|     Tom|\n",
      "|  4|      Ma|\n",
      "| 24|    Dull|\n",
      "| 54|    Kent|\n",
      "| 44|   Kient|\n",
      "| 74|    Anti|\n",
      "| 84|  Dirich|\n",
      "|  4|     Roy|\n",
      "| 94| Johnson|\n",
      "|104|     Die|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q3: write and sql query to show ID and LastName\n",
    "spark.sql(\" select ID, LastName from student_data \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+----------+\n",
      "| ID|FirstName|LastName|   Address|\n",
      "+---+---------+--------+----------+\n",
      "| 34|      Joe|   Kidde| Amsterdam|\n",
      "| 14|     Bide|     Tom|Kelifornia|\n",
      "|  4|     Jack|      Ma|  Oklahoma|\n",
      "| 24|     Dibb|    Dull|  New York|\n",
      "| 54|      Bob|    Kent|Kelifornia|\n",
      "| 44|     Hash|   Kient| Manhattan|\n",
      "| 74|     Joie|    Anti|New Jersey|\n",
      "| 84|    Biden|  Dirich|    Alaska|\n",
      "|  4|    Krish|     Roy|Birmingham|\n",
      "| 94|     Rock| Johnson|    London|\n",
      "|104|     John|     Die|    8Dhaka|\n",
      "+---+---------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q4: Write an sql queries to show all the columns and values\n",
    "spark.sql(\" select * from student_data \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  LastName|\n",
      "+----------+\n",
      "|    Dirich|\n",
      "|       Roy|\n",
      "|Kelifornia|\n",
      "|       Tom|\n",
      "|    London|\n",
      "|Birmingham|\n",
      "|  Oklahoma|\n",
      "|    Alaska|\n",
      "| Amsterdam|\n",
      "|      Anti|\n",
      "|        Ma|\n",
      "|    8Dhaka|\n",
      "|      Kent|\n",
      "|     Kient|\n",
      "|New Jersey|\n",
      "|     Kidde|\n",
      "|      Dull|\n",
      "|   Johnson|\n",
      "|       Die|\n",
      "|  New York|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q5: Write sql query to show last_name and address in one column\n",
    "spark.sql(\" (select LastName from student_data)\\\n",
    "            union \\\n",
    "            (select Address from student_data) \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|FirstName|\n",
      "+---------+\n",
      "|     Bide|\n",
      "|     Jack|\n",
      "|     Rock|\n",
      "|      Joe|\n",
      "|    Krish|\n",
      "|      Bob|\n",
      "|     John|\n",
      "|     Joie|\n",
      "|     Hash|\n",
      "|     Dibb|\n",
      "|    Biden|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q6: Write sql query to show unique first_name\n",
    "spark.sql(\" select distinct(FirstName) from student_data \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|FirstName|LastName|\n",
      "+---------+--------+\n",
      "|      Bob|    Kent|\n",
      "|     Dibb|    Dull|\n",
      "|     Bide|     Tom|\n",
      "|     John|     Die|\n",
      "|    Biden|  Dirich|\n",
      "|     Joie|    Anti|\n",
      "|      Joe|   Kidde|\n",
      "|     Rock| Johnson|\n",
      "|    Krish|     Roy|\n",
      "|     Jack|      Ma|\n",
      "|     Hash|   Kient|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q7: Write a sql query to show unique first_name and last_name\n",
    "spark.sql(\" select distinct FirstName, LastName from student_data \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+----------+\n",
      "| ID|FirstName|LastName|   Address|\n",
      "+---+---------+--------+----------+\n",
      "| 34|      Joe|   Kidde| Amsterdam|\n",
      "| 14|     Bide|     Tom|Kelifornia|\n",
      "|  4|     Jack|      Ma|  Oklahoma|\n",
      "| 24|     Dibb|    Dull|  New York|\n",
      "| 54|      Bob|    Kent|Kelifornia|\n",
      "+---+---------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q1: write an sql query to print first five rows \n",
    "spark.sql(\" select * from student_data limit 5 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+----------+\n",
      "| ID|FirstName|LastName|   Address|\n",
      "+---+---------+--------+----------+\n",
      "| 34|      Joe|   Kidde| Amsterdam|\n",
      "| 14|     Bide|     Tom|Kelifornia|\n",
      "|  4|     Jack|      Ma|  Oklahoma|\n",
      "+---+---------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q2: write an sql query to print first 3 persons data\n",
    "spark.sql(\" select * from student_data limit 3 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+----------+\n",
      "| ID|FirstName|LastName|   Address|\n",
      "+---+---------+--------+----------+\n",
      "| 34|      Joe|   Kidde| Amsterdam|\n",
      "| 14|     Bide|     Tom|Kelifornia|\n",
      "|  4|     Jack|      Ma|  Oklahoma|\n",
      "| 24|     Dibb|    Dull|  New York|\n",
      "| 54|      Bob|    Kent|Kelifornia|\n",
      "| 44|     Hash|   Kient| Manhattan|\n",
      "| 74|     Joie|    Anti|New Jersey|\n",
      "| 84|    Biden|  Dirich|    Alaska|\n",
      "|  4|    Krish|     Roy|Birmingham|\n",
      "| 94|     Rock| Johnson|    London|\n",
      "+---+---------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q3: write an sql query to show 6 to 10 data\n",
    "spark.sql(\" select * from student_data limit 10 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling with fully qualified name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|FirstName|\n",
      "+---------+\n",
      "|      Joe|\n",
      "|     Bide|\n",
      "|     Jack|\n",
      "|     Dibb|\n",
      "|      Bob|\n",
      "|     Hash|\n",
      "|     Joie|\n",
      "|    Biden|\n",
      "|    Krish|\n",
      "|     Rock|\n",
      "|     John|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q1: write an sql query to show FirstName with fully qualified name\n",
    "spark.sql(\" select student_data.FirstName from student_data \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|LastName|   Address|\n",
      "+--------+----------+\n",
      "|   Kidde| Amsterdam|\n",
      "|     Tom|Kelifornia|\n",
      "|      Ma|  Oklahoma|\n",
      "|    Dull|  New York|\n",
      "|    Kent|Kelifornia|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q2: write an sql query to show five LastName and Address\n",
    "spark.sql(\" select student_data.LastName, student_data.Address from student_data limit 5 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|FirstName|\n",
      "+---------+\n",
      "|     Jack|\n",
      "|    Krish|\n",
      "|     Bide|\n",
      "|     Dibb|\n",
      "|      Joe|\n",
      "|     Hash|\n",
      "|      Bob|\n",
      "|     Joie|\n",
      "|    Biden|\n",
      "|     Rock|\n",
      "|     John|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q1: write an sql query to show FirstName with sorting\n",
    "spark.sql(\" select FirstName from student_data order by ID \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|FirstName|   Address|\n",
      "+---------+----------+\n",
      "|     Bide|Kelifornia|\n",
      "|    Biden|    Alaska|\n",
      "|      Bob|Kelifornia|\n",
      "|     Dibb|  New York|\n",
      "|     Hash| Manhattan|\n",
      "|     Jack|  Oklahoma|\n",
      "|      Joe| Amsterdam|\n",
      "|     John|    8Dhaka|\n",
      "|     Joie|New Jersey|\n",
      "|    Krish|Birmingham|\n",
      "|     Rock|    London|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q2: Write an sql query to show FirstName, address and sort with first_name\n",
    "spark.sql(\" select FirstName, Address from student_data order by FirstName \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|FirstName|   Address|\n",
      "+---------+----------+\n",
      "|     Jack|  Oklahoma|\n",
      "|    Krish|Birmingham|\n",
      "|     Bide|Kelifornia|\n",
      "|     Dibb|  New York|\n",
      "|      Joe| Amsterdam|\n",
      "|     Hash| Manhattan|\n",
      "|      Bob|Kelifornia|\n",
      "|     Joie|New Jersey|\n",
      "|    Biden|    Alaska|\n",
      "|     Rock|    London|\n",
      "|     John|    8Dhaka|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q3: Write an sql query to show FirstName, address and sort with ID\n",
    "spark.sql(\" select FirstName, Address from student_data order by ID \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|FirstName|   Address|\n",
      "+---------+----------+\n",
      "|     John|    8Dhaka|\n",
      "|     Rock|    London|\n",
      "|    Biden|    Alaska|\n",
      "|     Joie|New Jersey|\n",
      "|      Bob|Kelifornia|\n",
      "|     Hash| Manhattan|\n",
      "|      Joe| Amsterdam|\n",
      "|     Dibb|  New York|\n",
      "|     Bide|Kelifornia|\n",
      "|     Jack|  Oklahoma|\n",
      "|    Krish|Birmingham|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q4: Write an sql query to show FirstName, address and descending sort with ID\n",
    "spark.sql(\" select FirstName, Address from student_data order by ID desc \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|FirstName|   Address|\n",
      "+---------+----------+\n",
      "|     Jack|  Oklahoma|\n",
      "|    Krish|Birmingham|\n",
      "|     Bide|Kelifornia|\n",
      "|     Dibb|  New York|\n",
      "|      Joe| Amsterdam|\n",
      "|     Hash| Manhattan|\n",
      "|      Bob|Kelifornia|\n",
      "|     Joie|New Jersey|\n",
      "|    Biden|    Alaska|\n",
      "|     Rock|    London|\n",
      "|     John|    8Dhaka|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q5: Write an sql query to show FirstName, address and ascending sort with ID\n",
    "spark.sql(\" select FirstName, Address from student_data order by ID asc \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|FirstName|   Address|\n",
      "+---------+----------+\n",
      "|     Jack|  Oklahoma|\n",
      "|    Krish|Birmingham|\n",
      "|     Bide|Kelifornia|\n",
      "|     Dibb|  New York|\n",
      "|      Joe| Amsterdam|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q6: Write an sql query to show FirstName, address and ascending sort with ID, take 5\n",
    "spark.sql(\" select FirstName, Address from student_data order by ID asc limit 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|FirstName|Address|\n",
      "+---------+-------+\n",
      "|     John| 8Dhaka|\n",
      "|     Rock| London|\n",
      "|    Biden| Alaska|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q7: Write an sql query to show FirstName, address and descending sort with ID, limit 3\n",
    "spark.sql(\" select FirstName, Address from student_data order by ID desc limit 3\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|FirstName|   Address|\n",
      "+---------+----------+\n",
      "|     Bide|Kelifornia|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q1: write an sql query to show first_name, address where id=14\n",
    "spark.sql(\" select FirstName, Address from student_data where ID=14 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+\n",
      "| ID|LastName|   Address|\n",
      "+---+--------+----------+\n",
      "| 54|    Kent|Kelifornia|\n",
      "| 74|    Anti|New Jersey|\n",
      "| 84|  Dirich|    Alaska|\n",
      "| 94| Johnson|    London|\n",
      "|104|     Die|    8Dhaka|\n",
      "+---+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q2: write and sql query to show id, last_name and address where id>50\n",
    "spark.sql(\" select ID, LastName, Address from student_data where ID>50 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of between, and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| ID|FirstName|\n",
      "+---+---------+\n",
      "| 54|      Bob|\n",
      "| 44|     Hash|\n",
      "| 74|     Joie|\n",
      "+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q1: write an sql query to show id, first_name where id between 40 and 80\n",
    "spark.sql(\" select ID, FirstName from student_data where ID between 40 and 80 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| ID|FirstName|\n",
      "+---+---------+\n",
      "| 54|      Bob|\n",
      "| 44|     Hash|\n",
      "| 74|     Joie|\n",
      "+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q2: write an sql query to show id, first_name where id between 40 and 80\n",
    "spark.sql(\" select ID, FirstName from student_data where ID between 40 and 80 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| ID|FirstName|\n",
      "+---+---------+\n",
      "| 24|     Dibb|\n",
      "+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q3: write an sql query to show id, first_name where first_name=Dibb and last_name=Dull\n",
    "spark.sql(\" select ID, FirstName from student_data where FirstName='Dibb' and LastName='Dull' \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| ID|FirstName|\n",
      "+---+---------+\n",
      "| 84|    Biden|\n",
      "+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q1: write an sql query to show id, first_name where id=44 or id=84 and name='Biden'\n",
    "spark.sql(\" select ID, FirstName from student_data where (ID=44 or ID=84) and FirstName='Biden' \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|FirstName|LastName|\n",
      "+---------+--------+\n",
      "|      Bob|    Kent|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q2: write and sql query to show First_name, Last_name ID=74 or ID=54 or ID=94 and Last_name='Kent'\n",
    "spark.sql(\" select FirstName, LastName from student_data where (ID=74 or ID=54 or ID=94) and LastName='Kent' \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+--------+\n",
      "|FirstName| ID|LastName|\n",
      "+---------+---+--------+\n",
      "|     Hash| 44|   Kient|\n",
      "+---------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q3: write an sql query to show first_name, id, last_name where ID between 30 to 70 or id=84 and last_name='Kient' \n",
    "spark.sql(\" select FirstName, ID, LastName from student_data where ((ID between 30 and 70) or ID=112) and LastName='Kient' \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of in, not in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+\n",
      "| ID|FirstName|   Address|\n",
      "+---+---------+----------+\n",
      "| 14|     Bide|Kelifornia|\n",
      "| 24|     Dibb|  New York|\n",
      "| 74|     Joie|New Jersey|\n",
      "+---+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q1: write an sql query to show id, first_name and address where LastName=(Anti, Tom, Dull)\n",
    "spark.sql(\" select ID, FirstName, Address from student_data where LastName in ('Anti', 'Tom', 'Dull') \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+\n",
      "| ID|FirstName|   Address|\n",
      "+---+---------+----------+\n",
      "| 34|      Joe| Amsterdam|\n",
      "|  4|     Jack|  Oklahoma|\n",
      "| 54|      Bob|Kelifornia|\n",
      "| 44|     Hash| Manhattan|\n",
      "| 84|    Biden|    Alaska|\n",
      "|  4|    Krish|Birmingham|\n",
      "| 94|     Rock|    London|\n",
      "|104|     John|    8Dhaka|\n",
      "+---+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q2: write an sql query to show ID, first_name and address where last name not in (Anti, Tom, Dull)\n",
    "spark.sql(\" select ID, FirstName, Address from student_data where LastName not in ('Anti', 'Tom', 'Dull') \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| ID|FirstName|\n",
      "+---+---------+\n",
      "| 24|     Dibb|\n",
      "+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q1: write an sql query to show ID, first_name where last part of the address is York\n",
    "spark.sql(\" select ID, FirstName from student_data where Address like '%York' \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| ID|FirstName|\n",
      "+---+---------+\n",
      "| 44|     Hash|\n",
      "+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q2: write an sql query to show ID, first_name where address have substring that is hatt\n",
    "spark.sql(\" select ID, FirstName from student_data where Address like '%hatt%' \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| ID|FirstName|\n",
      "+---+---------+\n",
      "|104|     John|\n",
      "+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q3: write an sql query to show ID, first_name where address is 89 Dhaka\n",
    "spark.sql(\" select ID, FirstName from student_data where Address like '_Dhaka' \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: _(underscore) take only one digit integer number like 3,5,6,7,4,3, for this % is better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
