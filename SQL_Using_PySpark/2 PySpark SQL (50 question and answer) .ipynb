{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.functions import unix_timestamp\n",
    "from pyspark.sql.functions import from_unixtime\n",
    "from pyspark.sql.types import DoubleType, IntegerType, DateType, TimestampType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"PySpark SQL Table Joining\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing File Type and path for data train\n",
    "file_type = 'text'\n",
    "delimeter=','\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_type):\n",
    "    \"\"\"input type of file \"text\" or \"parquet\" and Return pyspark dataframe\"\"\"\n",
    "    if file_type ==\"text\": # use text as file type input\n",
    "        df = spark.read.option(\"header\", \"true\") \\\n",
    "                       .option(\"delimeter\",delimeter)\\\n",
    "                       .option(\"inferSchema\", \"true\") \\\n",
    "                       .csv(path)  #path file that you want import\n",
    "    else:  \n",
    "        df= spark.read.parquet(\"example.parquet\") #path file that you want import\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading worker dataset\n",
    "path=r'/home/hasan/DATA SET/PySpark SQL/Worker.csv'\n",
    "worker = load_data(file_type)\n",
    "\n",
    "# reading title dataset\n",
    "path = r'/home/hasan/DATA SET/PySpark SQL/Title.csv'\n",
    "title = load_data(file_type)\n",
    "\n",
    "# reading bonus dataset\n",
    "path = r'/home/hasan/DATA SET/PySpark SQL/Bonus.csv'\n",
    "bonus = load_data(file_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting to DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker = worker.withColumn(\"JOINING_DATE\", worker[\"JOINING_DATE\"].cast(DateType()))\n",
    "title = title.withColumn(\"AFFECTED_FROM\", title[\"AFFECTED_FROM\"].cast(DateType()))\n",
    "bonus = bonus.withColumn(\"BONUS_DATE\", bonus[\"BONUS_DATE\"].cast(DateType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+\n",
      "|WORKER_ID|FIRST_NAME|LAST_NAME|SALARY|JOINING_DATE|DEPARTMENT|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "|        1|    Monika|    Arora|100000|  2014-07-25|        HR|\n",
      "|        2|  Niharika|    Verma| 80000|  2014-08-24|     Admin|\n",
      "|        3|    Vishal|  Singhal|300000|  2014-02-16|        HR|\n",
      "|        4|   Amitabh|    Singh|500000|  2014-05-09|     Admin|\n",
      "|        5|     Vivek|    Bhati|500000|  2014-07-12|     Admin|\n",
      "|        6|     Vipul|    Diwan|200000|  2014-11-16|   Account|\n",
      "|        7|    Satish|    Kumar| 75000|  2014-09-19|   Account|\n",
      "|        8|   Geetika|  Chauhan| 90000|  2014-03-22|     Admin|\n",
      "|        9|     Subro|      Roy| 75000|  2014-10-21|   Account|\n",
      "|       10|  Soumitro|      Das| 84000|  2014-04-13|     Admin|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "worker.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+-------------+\n",
      "|WORKER_REF_ID| WORKER_TITLE|AFFECTED_FROM|\n",
      "+-------------+-------------+-------------+\n",
      "|            1|      Manager|   2016-02-20|\n",
      "|            2|    Executive|   2016-06-11|\n",
      "|            8|    Executive|   2016-06-11|\n",
      "|           10|         Lead|   2016-06-20|\n",
      "|            5|      Manager|   2016-06-11|\n",
      "|            4|Asst. Manager|   2016-06-11|\n",
      "|            9|      Manager|   2016-03-20|\n",
      "|            7|    Executive|   2016-06-11|\n",
      "|            6|         Lead|   2016-06-11|\n",
      "|            3|         Lead|   2016-06-11|\n",
      "+-------------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------------+\n",
      "|WORKER_REF_ID|BONUS_DATE|BONUS_AMOUNT|\n",
      "+-------------+----------+------------+\n",
      "|            1|2014-07-25|        5000|\n",
      "|            2|2014-08-24|        3000|\n",
      "|            3|2014-02-16|        4000|\n",
      "|            1|2014-07-25|        4500|\n",
      "|            2|2014-08-24|        3500|\n",
      "+-------------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bonus.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- WORKER_ID: integer (nullable = true)\n",
      " |-- FIRST_NAME: string (nullable = true)\n",
      " |-- LAST_NAME: string (nullable = true)\n",
      " |-- SALARY: integer (nullable = true)\n",
      " |-- JOINING_DATE: date (nullable = true)\n",
      " |-- DEPARTMENT: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "worker.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- WORKER_REF_ID: integer (nullable = true)\n",
      " |-- WORKER_TITLE: string (nullable = true)\n",
      " |-- AFFECTED_FROM: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- WORKER_REF_ID: integer (nullable = true)\n",
      " |-- BONUS_DATE: date (nullable = true)\n",
      " |-- BONUS_AMOUNT: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bonus.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Dataset to SQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the DataFrame as a SQL temporary view\n",
    "worker.createOrReplaceTempView(\"worker_data\")\n",
    "title.createOrReplaceTempView(\"title_data\")\n",
    "bonus.createOrReplaceTempView(\"bonus_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question and Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|WORKER_NAME|\n",
      "+-----------+\n",
      "|     Monika|\n",
      "|   Niharika|\n",
      "|     Vishal|\n",
      "|    Amitabh|\n",
      "|      Vivek|\n",
      "|      Vipul|\n",
      "|     Satish|\n",
      "|    Geetika|\n",
      "|      Subro|\n",
      "|   Soumitro|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q-1. Write an SQL query to fetch “FIRST_NAME” from Worker table using the alias name as <WORKER_NAME>.\n",
    "spark.sql(\" select FIRST_NAME as WORKER_NAME from worker_data \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|upper(FIRST_NAME)|\n",
      "+-----------------+\n",
      "|           MONIKA|\n",
      "|         NIHARIKA|\n",
      "|           VISHAL|\n",
      "|          AMITABH|\n",
      "|            VIVEK|\n",
      "|            VIPUL|\n",
      "|           SATISH|\n",
      "|          GEETIKA|\n",
      "|            SUBRO|\n",
      "|         SOUMITRO|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q-2. Write an SQL query to fetch “FIRST_NAME” from Worker table in upper case.\n",
    "spark.sql(\" select upper(FIRST_NAME) from worker_data \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|DEPARTMENT|\n",
      "+----------+\n",
      "|        HR|\n",
      "|     Admin|\n",
      "|   Account|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q-3. Write an SQL query to fetch unique values of DEPARTMENT from Worker table.\n",
    "spark.sql(\" select distinct(DEPARTMENT) from worker_data \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|substring(FIRST_NAME, 1, 3)|\n",
      "+---------------------------+\n",
      "|                        Mon|\n",
      "|                        Nih|\n",
      "|                        Vis|\n",
      "|                        Ami|\n",
      "|                        Viv|\n",
      "|                        Vip|\n",
      "|                        Sat|\n",
      "|                        Gee|\n",
      "|                        Sub|\n",
      "|                        Sou|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-4. Write an SQL query to print the first three characters of  FIRST_NAME from Worker table.\n",
    "spark.sql(\" select substring(FIRST_NAME,1,3) from worker_data \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|instr(FIRST_NAME, a)|\n",
      "+--------------------+\n",
      "|                   5|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-5. Write an SQL query to find the position of the alphabet (‘a’) in the first name column ‘Amitabh’ from Worker table.\n",
    "spark.sql(\" Select instr(FIRST_NAME, 'a') from worker_data where FIRST_NAME = 'Amitabh' \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|rtrim(FIRST_NAME)|\n",
      "+-----------------+\n",
      "|           Monika|\n",
      "|         Niharika|\n",
      "|           Vishal|\n",
      "|          Amitabh|\n",
      "|            Vivek|\n",
      "|            Vipul|\n",
      "|           Satish|\n",
      "|          Geetika|\n",
      "|            Subro|\n",
      "|         Soumitro|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-6. Write an SQL query to print the FIRST_NAME from Worker table after removing white spaces from the right side.\n",
    "spark.sql(\" Select RTRIM(FIRST_NAME) from worker_data \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|ltrim(DEPARTMENT)|\n",
      "+-----------------+\n",
      "|               HR|\n",
      "|            Admin|\n",
      "|               HR|\n",
      "|            Admin|\n",
      "|            Admin|\n",
      "|          Account|\n",
      "|          Account|\n",
      "|            Admin|\n",
      "|          Account|\n",
      "|            Admin|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-7. Write an SQL query to print the DEPARTMENT from Worker table after removing white spaces from the left side.\n",
    "spark.sql(\" select ltrim(DEPARTMENT) from worker_data \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|length(DEPARTMENT)|\n",
      "+------------------+\n",
      "|                 5|\n",
      "|                 7|\n",
      "|                 2|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-8. Write an SQL query that fetches the unique values of DEPARTMENT from Worker table and prints its length.\n",
    "spark.sql(\" select distinct length(DEPARTMENT) from worker_data \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|replace(FIRST_NAME, a, A)|\n",
      "+-------------------------+\n",
      "|                   MonikA|\n",
      "|                 NihArikA|\n",
      "|                   VishAl|\n",
      "|                  AmitAbh|\n",
      "|                    Vivek|\n",
      "|                    Vipul|\n",
      "|                   SAtish|\n",
      "|                  GeetikA|\n",
      "|                    Subro|\n",
      "|                 Soumitro|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-9. Write an SQL query to print the FIRST_NAME from Worker table after replacing ‘a’ with ‘A’.\n",
    "spark.sql(\" select replace(FIRST_NAME, 'a', 'A') from worker_data\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|  COMPLETE_NAME|\n",
      "+---------------+\n",
      "|   Monika Arora|\n",
      "| Niharika Verma|\n",
      "| Vishal Singhal|\n",
      "|  Amitabh Singh|\n",
      "|    Vivek Bhati|\n",
      "|    Vipul Diwan|\n",
      "|   Satish Kumar|\n",
      "|Geetika Chauhan|\n",
      "|      Subro Roy|\n",
      "|   Soumitro Das|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-10. Write an SQL query to print the FIRST_NAME and LAST_NAME from Worker table into a single column COMPLETE_NAME. A space char should separate them.\n",
    "spark.sql(\" select concat(FIRST_NAME, ' ', LAST_NAME) as COMPLETE_NAME from worker_data \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+\n",
      "|WORKER_ID|FIRST_NAME|LAST_NAME|SALARY|JOINING_DATE|DEPARTMENT|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "|        4|   Amitabh|    Singh|500000|  2014-05-09|     Admin|\n",
      "|        8|   Geetika|  Chauhan| 90000|  2014-03-22|     Admin|\n",
      "|        1|    Monika|    Arora|100000|  2014-07-25|        HR|\n",
      "|        2|  Niharika|    Verma| 80000|  2014-08-24|     Admin|\n",
      "|        7|    Satish|    Kumar| 75000|  2014-09-19|   Account|\n",
      "|       10|  Soumitro|      Das| 84000|  2014-04-13|     Admin|\n",
      "|        9|     Subro|      Roy| 75000|  2014-10-21|   Account|\n",
      "|        6|     Vipul|    Diwan|200000|  2014-11-16|   Account|\n",
      "|        3|    Vishal|  Singhal|300000|  2014-02-16|        HR|\n",
      "|        5|     Vivek|    Bhati|500000|  2014-07-12|     Admin|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-11. Write an SQL query to print all Worker details from the Worker table order by FIRST_NAME Ascending.\n",
    "spark.sql(\" select * from worker_data order by FIRST_NAME asc \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+\n",
      "|WORKER_ID|FIRST_NAME|LAST_NAME|SALARY|JOINING_DATE|DEPARTMENT|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "|        4|   Amitabh|    Singh|500000|  2014-05-09|     Admin|\n",
      "|        8|   Geetika|  Chauhan| 90000|  2014-03-22|     Admin|\n",
      "|        1|    Monika|    Arora|100000|  2014-07-25|        HR|\n",
      "|        2|  Niharika|    Verma| 80000|  2014-08-24|     Admin|\n",
      "|        7|    Satish|    Kumar| 75000|  2014-09-19|   Account|\n",
      "|       10|  Soumitro|      Das| 84000|  2014-04-13|     Admin|\n",
      "|        9|     Subro|      Roy| 75000|  2014-10-21|   Account|\n",
      "|        6|     Vipul|    Diwan|200000|  2014-11-16|   Account|\n",
      "|        3|    Vishal|  Singhal|300000|  2014-02-16|        HR|\n",
      "|        5|     Vivek|    Bhati|500000|  2014-07-12|     Admin|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-12. Write an SQL query to print all Worker details from the Worker table order by FIRST_NAME Ascending and DEPARTMENT Descending.\n",
    "spark.sql(\" select * from worker_data order by FIRST_NAME asc, DEPARTMENT desc \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+\n",
      "|WORKER_ID|FIRST_NAME|LAST_NAME|SALARY|JOINING_DATE|DEPARTMENT|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "|        6|     Vipul|    Diwan|200000|  2014-11-16|   Account|\n",
      "|        7|    Satish|    Kumar| 75000|  2014-09-19|   Account|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-13. Write an SQL query to print details for Workers with the first name as “Vipul” and “Satish” from Worker table.\n",
    "spark.sql(\" select * from worker_data where FIRST_NAME in ('Vipul', 'Satish') \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+\n",
      "|WORKER_ID|FIRST_NAME|LAST_NAME|SALARY|JOINING_DATE|DEPARTMENT|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "|        1|    Monika|    Arora|100000|  2014-07-25|        HR|\n",
      "|        2|  Niharika|    Verma| 80000|  2014-08-24|     Admin|\n",
      "|        3|    Vishal|  Singhal|300000|  2014-02-16|        HR|\n",
      "|        4|   Amitabh|    Singh|500000|  2014-05-09|     Admin|\n",
      "|        5|     Vivek|    Bhati|500000|  2014-07-12|     Admin|\n",
      "|        8|   Geetika|  Chauhan| 90000|  2014-03-22|     Admin|\n",
      "|        9|     Subro|      Roy| 75000|  2014-10-21|   Account|\n",
      "|       10|  Soumitro|      Das| 84000|  2014-04-13|     Admin|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-14. Write an SQL query to print details of workers excluding first names, “Vipul” and “Satish” from Worker table.\n",
    "spark.sql(\" select * from worker_data where FIRST_NAME not in ('Vipul', 'Satish') \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+\n",
      "|WORKER_ID|FIRST_NAME|LAST_NAME|SALARY|JOINING_DATE|DEPARTMENT|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "|        2|  Niharika|    Verma| 80000|  2014-08-24|     Admin|\n",
      "|        4|   Amitabh|    Singh|500000|  2014-05-09|     Admin|\n",
      "|        5|     Vivek|    Bhati|500000|  2014-07-12|     Admin|\n",
      "|        8|   Geetika|  Chauhan| 90000|  2014-03-22|     Admin|\n",
      "|       10|  Soumitro|      Das| 84000|  2014-04-13|     Admin|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-15. Write an SQL query to print details of Workers with DEPARTMENT name as “Admin”.\n",
    "spark.sql(\" select * from worker_data where DEPARTMENT='Admin' \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+\n",
      "|WORKER_ID|FIRST_NAME|LAST_NAME|SALARY|JOINING_DATE|DEPARTMENT|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "|        1|    Monika|    Arora|100000|  2014-07-25|        HR|\n",
      "|        2|  Niharika|    Verma| 80000|  2014-08-24|     Admin|\n",
      "|        3|    Vishal|  Singhal|300000|  2014-02-16|        HR|\n",
      "|        4|   Amitabh|    Singh|500000|  2014-05-09|     Admin|\n",
      "|        7|    Satish|    Kumar| 75000|  2014-09-19|   Account|\n",
      "|        8|   Geetika|  Chauhan| 90000|  2014-03-22|     Admin|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-16. Write an SQL query to print details of the Workers whose FIRST_NAME contains ‘a’.\n",
    "spark.sql(\" select * from worker_data where FIRST_NAME like '%a%' \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+\n",
      "|WORKER_ID|FIRST_NAME|LAST_NAME|SALARY|JOINING_DATE|DEPARTMENT|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "|        1|    Monika|    Arora|100000|  2014-07-25|        HR|\n",
      "|        2|  Niharika|    Verma| 80000|  2014-08-24|     Admin|\n",
      "|        8|   Geetika|  Chauhan| 90000|  2014-03-22|     Admin|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-17. Write an SQL query to print details of the Workers whose FIRST_NAME ends with ‘a’.\n",
    "spark.sql(\" select * from worker_data where FIRST_NAME like '%a' \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+\n",
      "|WORKER_ID|FIRST_NAME|LAST_NAME|SALARY|JOINING_DATE|DEPARTMENT|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "|        7|    Satish|    Kumar| 75000|  2014-09-19|   Account|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-18. Write an SQL query to print details of the Workers whose FIRST_NAME ends with ‘h’ and contains six alphabets.\n",
    "spark.sql(\" select * from worker_data where FIRST_NAME like '_____h' \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+\n",
      "|WORKER_ID|FIRST_NAME|LAST_NAME|SALARY|JOINING_DATE|DEPARTMENT|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "|        1|    Monika|    Arora|100000|  2014-07-25|        HR|\n",
      "|        3|    Vishal|  Singhal|300000|  2014-02-16|        HR|\n",
      "|        4|   Amitabh|    Singh|500000|  2014-05-09|     Admin|\n",
      "|        5|     Vivek|    Bhati|500000|  2014-07-12|     Admin|\n",
      "|        6|     Vipul|    Diwan|200000|  2014-11-16|   Account|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-19. Write an SQL query to print details of the Workers whose SALARY lies between 100000 and 500000.\n",
    "spark.sql(\" select * from worker_data where SALARY between 100000 and 500000 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+\n",
      "|WORKER_ID|FIRST_NAME|LAST_NAME|SALARY|JOINING_DATE|DEPARTMENT|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "|        3|    Vishal|  Singhal|300000|  2014-02-16|        HR|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-20. Write an SQL query to print details of the Workers who have joined in Feb’2014.\n",
    "spark.sql(\" select * from worker_data where year(JOINING_DATE)=2014 and month(JOINING_DATE)=2 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       5|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-21. Write an SQL query to fetch the count of employees working in the department ‘Admin’.\n",
    "spark.sql(\" select count(*) from worker_data where DEPARTMENT='Admin' \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|FIRST_NAME|\n",
      "+----------+\n",
      "|    Monika|\n",
      "|  Niharika|\n",
      "|    Satish|\n",
      "|   Geetika|\n",
      "|     Subro|\n",
      "|  Soumitro|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-22. Write an SQL query to fetch worker names with salaries >= 50000 and <= 100000.\n",
    "spark.sql(\" select FIRST_NAME from worker_data where SALARY>=50000 and SALARY<=100000 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|DEPARTMENT|no_worker|\n",
      "+----------+---------+\n",
      "|     Admin|        5|\n",
      "|   Account|        3|\n",
      "|        HR|        2|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-23. Write an SQL query to fetch the no. of workers for each department in the descending order.\n",
    "spark.sql(\" select DEPARTMENT,  count(WORKER_ID) no_worker from worker_data group by DEPARTMENT order by no_worker desc \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|no_worker|\n",
      "+---------+\n",
      "|        5|\n",
      "|        3|\n",
      "|        2|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-23. Write an SQL query to fetch the no. of workers for each department in the descending order.\n",
    "spark.sql(\" select count(DEPARTMENT) no_worker from worker_data group by DEPARTMENT order by no_worker desc \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+-------------+------------+-------------+\n",
      "|WORKER_ID|FIRST_NAME|LAST_NAME|SALARY|JOINING_DATE|DEPARTMENT|WORKER_REF_ID|WORKER_TITLE|AFFECTED_FROM|\n",
      "+---------+----------+---------+------+------------+----------+-------------+------------+-------------+\n",
      "|        1|    Monika|    Arora|100000|  2014-07-25|        HR|            1|     Manager|   2016-02-20|\n",
      "|        5|     Vivek|    Bhati|500000|  2014-07-12|     Admin|            5|     Manager|   2016-06-11|\n",
      "|        9|     Subro|      Roy| 75000|  2014-10-21|   Account|            9|     Manager|   2016-03-20|\n",
      "+---------+----------+---------+------+------------+----------+-------------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-24. Write an SQL query to print details of the Workers who are also Managers.\n",
    "spark.sql(\" select * from worker_data w inner join title_data t on w.WORKER_ID=t.WORKER_REF_ID and t.WORKER_TITLE='Manager' \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|FIRST_NAME|WORKER_TITLE|\n",
      "+----------+------------+\n",
      "|    Monika|     Manager|\n",
      "|     Vivek|     Manager|\n",
      "|     Subro|     Manager|\n",
      "+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-24. Write an SQL query to print details of the Workers who are also Managers.\n",
    "spark.sql(\" select w.FIRST_NAME, T.WORKER_TITLE from worker_data w inner join title_data t on w.WORKER_ID=t.WORKER_REF_ID and t.WORKER_TITLE='Manager' \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+--------+\n",
      "|WORKER_TITLE|AFFECTED_FROM|count(1)|\n",
      "+------------+-------------+--------+\n",
      "|   Executive|   2016-06-11|       3|\n",
      "|        Lead|   2016-06-11|       2|\n",
      "+------------+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-25. Write an SQL query to fetch duplicate records having matching data in some fields of a table.\n",
    "spark.sql(\" select WORKER_TITLE, AFFECTED_FROM, count(*) from title_data group by WORKER_TITLE, AFFECTED_FROM having count(*) > 1 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|DEPARTMENT|count(1)|\n",
      "+----------+--------+\n",
      "|        HR|       2|\n",
      "|     Admin|       5|\n",
      "|   Account|       3|\n",
      "+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-25 Write and SQL query to find department name which are appear more than 1 times.\n",
    "spark.sql(\" SELECT DEPARTMENT, COUNT(*) FROM worker_data GROUP BY DEPARTMENT HAVING COUNT(*) > 1 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+\n",
      "|WORKER_ID|FIRST_NAME|LAST_NAME|SALARY|JOINING_DATE|DEPARTMENT|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "|        1|    Monika|    Arora|100000|  2014-07-25|        HR|\n",
      "|        3|    Vishal|  Singhal|300000|  2014-02-16|        HR|\n",
      "|        5|     Vivek|    Bhati|500000|  2014-07-12|     Admin|\n",
      "|        7|    Satish|    Kumar| 75000|  2014-09-19|   Account|\n",
      "|        9|     Subro|      Roy| 75000|  2014-10-21|   Account|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-26. Write an SQL query to show only odd rows from a table.\n",
    "spark.sql(\" select * from worker_data where mod(WORKER_ID, 2)<>0 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+\n",
      "|WORKER_ID|FIRST_NAME|LAST_NAME|SALARY|JOINING_DATE|DEPARTMENT|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "|        2|  Niharika|    Verma| 80000|  2014-08-24|     Admin|\n",
      "|        4|   Amitabh|    Singh|500000|  2014-05-09|     Admin|\n",
      "|        6|     Vipul|    Diwan|200000|  2014-11-16|   Account|\n",
      "|        8|   Geetika|  Chauhan| 90000|  2014-03-22|     Admin|\n",
      "|       10|  Soumitro|      Das| 84000|  2014-04-13|     Admin|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-27. Write an SQL query to show only even rows from a table.\n",
    "spark.sql(\" select * from worker_data where mod(WORKER_ID, 2)=0 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below two question is not possible because those table have date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q-29. Write an SQL query to fetch intersecting records of two tables.\n",
    "spark.sql(\" (SELECT * FROM bonus_data) INTERSECT (SELECT * FROM title_data) \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-30. Write an SQL query to show records from one table that another table does not have.\n",
    "spark.sql(\" (select * from bonus_data) minus (select * from title_data) \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               now()|\n",
      "+--------------------+\n",
      "|2020-07-27 22:48:...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-31. Write an SQL query to show the current date and time.\n",
    "spark.sql(\" SELECT NOW() \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+\n",
      "|WORKER_ID|FIRST_NAME|LAST_NAME|SALARY|JOINING_DATE|DEPARTMENT|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "|        7|    Satish|    Kumar| 75000|  2014-09-19|   Account|\n",
      "|        9|     Subro|      Roy| 75000|  2014-10-21|   Account|\n",
      "|        2|  Niharika|    Verma| 80000|  2014-08-24|     Admin|\n",
      "|       10|  Soumitro|      Das| 84000|  2014-04-13|     Admin|\n",
      "|        8|   Geetika|  Chauhan| 90000|  2014-03-22|     Admin|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-32. Write an SQL query to show the top n (say 10) records of a table.\n",
    "spark.sql(\" select * from worker_data order by SALARY limit 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|SALARY|\n",
      "+------+\n",
      "| 75000|\n",
      "| 75000|\n",
      "| 80000|\n",
      "| 84000|\n",
      "| 90000|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-33. Write an SQL query to determine the nth (say n=5) highest salary from a table.\n",
    "spark.sql(\" select SALARY from worker_data order by SALARY limit 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------+\n",
      "|WORKER_ID|FIRST_NAME|SALARY|\n",
      "+---------+----------+------+\n",
      "|        7|    Satish| 75000|\n",
      "|        9|     Subro| 75000|\n",
      "|        5|     Vivek|500000|\n",
      "|        4|   Amitabh|500000|\n",
      "+---------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-35. Write an SQL query to fetch the list of employees with the same salary.\n",
    "spark.sql(\" select distinct W.WORKER_ID, W.FIRST_NAME, W.SALARY from worker_data W, worker_data W1 where W.SALARY=W1.SALARY and W.WORKER_ID != W1.WORKER_ID \").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|max(SALARY)|\n",
      "+-----------+\n",
      "|     300000|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-36. Write an SQL query to show the second highest salary from a table.\n",
    "spark.sql(\" select max(SALARY) from worker_data where SALARY not in (select max(SALARY) from worker_data) \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|FIRST_NAME|SALARY|\n",
      "+----------+------+\n",
      "|    Monika|100000|\n",
      "|  Niharika| 80000|\n",
      "|    Vishal|300000|\n",
      "|   Amitabh|500000|\n",
      "|     Vivek|500000|\n",
      "|     Vipul|200000|\n",
      "|    Satish| 75000|\n",
      "|   Geetika| 90000|\n",
      "|     Subro| 75000|\n",
      "|  Soumitro| 84000|\n",
      "|    Monika|100000|\n",
      "|  Niharika| 80000|\n",
      "|    Vishal|300000|\n",
      "|   Amitabh|500000|\n",
      "|     Vivek|500000|\n",
      "|     Vipul|200000|\n",
      "|    Satish| 75000|\n",
      "|   Geetika| 90000|\n",
      "|     Subro| 75000|\n",
      "|  Soumitro| 84000|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-37. Write an SQL query to show one row twice in results from a table.\n",
    "spark.sql(\" (select FIRST_NAME, SALARY from worker_data W1) union all (select FIRST_NAME, SALARY from worker_data W2) \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### below question is not possible because table have date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-38. Write an SQL query to fetch intersecting records of two tables.\n",
    "spark.sql(\" (select * from title_data) intersect (select * from bonus_data) \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+\n",
      "|WORKER_ID|FIRST_NAME|LAST_NAME|SALARY|JOINING_DATE|DEPARTMENT|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "|        6|     Vipul|    Diwan|200000|  2014-11-16|   Account|\n",
      "|        7|    Satish|    Kumar| 75000|  2014-09-19|   Account|\n",
      "|        8|   Geetika|  Chauhan| 90000|  2014-03-22|     Admin|\n",
      "|        9|     Subro|      Roy| 75000|  2014-10-21|   Account|\n",
      "|       10|  Soumitro|      Das| 84000|  2014-04-13|     Admin|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-39. Write an SQL query to fetch the first 50% records from a table.\n",
    "spark.sql(\" select * from worker_data where WORKER_ID > (select count(WORKER_ID)/2 from worker_data) \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+\n",
      "|DEPARTMENT|number_of_worker|\n",
      "+----------+----------------+\n",
      "|        HR|               2|\n",
      "|   Account|               3|\n",
      "+----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-40. Write an SQL query to fetch the departments that have less than five people in it.\n",
    "spark.sql(\" select DEPARTMENT, count(WORKER_ID) as number_of_worker from worker_data group by DEPARTMENT having count(WORKER_ID)< 5 \").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|DEPARTMENT|Number_of_Workers|\n",
      "+----------+-----------------+\n",
      "|     Admin|                5|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-40. Write an SQL query to fetch the departments that have greater than four people in it.\n",
    "spark.sql(\" SELECT DEPARTMENT, COUNT(WORKER_ID) as Number_of_Workers FROM worker_data GROUP BY DEPARTMENT HAVING COUNT(WORKER_ID) >= 5 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|DEPARTMENT|number_employee|\n",
      "+----------+---------------+\n",
      "|        HR|              2|\n",
      "|     Admin|              5|\n",
      "|   Account|              3|\n",
      "+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-41. Write an SQL query to show all departments along with the number of people in there.\n",
    "spark.sql(\" select DEPARTMENT, count(DEPARTMENT) as number_employee from worker_data group by DEPARTMENT \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+\n",
      "|WORKER_ID|FIRST_NAME|LAST_NAME|SALARY|JOINING_DATE|DEPARTMENT|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "|       10|  Soumitro|      Das| 84000|  2014-04-13|     Admin|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-42. Write an SQL query to show the last record from a table.\n",
    "spark.sql(\" select * from worker_data where WORKER_ID = (select max(WORKER_ID) from worker_data) \").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+\n",
      "|WORKER_ID|FIRST_NAME|LAST_NAME|SALARY|JOINING_DATE|DEPARTMENT|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "|        1|    Monika|    Arora|100000|  2014-07-25|        HR|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-43. Write an SQL query to fetch the first row of a table.\n",
    "spark.sql(\" select * from worker_data where WORKER_ID=(select min(WORKER_ID) from worker_data) \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+\n",
      "|WORKER_ID|FIRST_NAME|LAST_NAME|SALARY|JOINING_DATE|DEPARTMENT|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "|        5|     Vivek|    Bhati|500000|  2014-07-12|     Admin|\n",
      "|        6|     Vipul|    Diwan|200000|  2014-11-16|   Account|\n",
      "|        7|    Satish|    Kumar| 75000|  2014-09-19|   Account|\n",
      "|        8|   Geetika|  Chauhan| 90000|  2014-03-22|     Admin|\n",
      "|        9|     Subro|      Roy| 75000|  2014-10-21|   Account|\n",
      "|       10|  Soumitro|      Das| 84000|  2014-04-13|     Admin|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-44. Write an SQL query to fetch the last five records from a table.\n",
    "spark.sql(\" select * from worker_data where WORKER_ID>=5 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+\n",
      "|WORKER_ID|FIRST_NAME|LAST_NAME|SALARY|JOINING_DATE|DEPARTMENT|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "|        5|     Vivek|    Bhati|500000|  2014-07-12|     Admin|\n",
      "|        2|  Niharika|    Verma| 80000|  2014-08-24|     Admin|\n",
      "|        3|    Vishal|  Singhal|300000|  2014-02-16|        HR|\n",
      "|        4|   Amitabh|    Singh|500000|  2014-05-09|     Admin|\n",
      "|        1|    Monika|    Arora|100000|  2014-07-25|        HR|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-44. Write an SQL query to fetch the last five records from a table.\n",
    "spark.sql(\" SELECT * FROM worker_data WHERE WORKER_ID <=5 UNION SELECT * FROM (SELECT * FROM worker_data W order by W.WORKER_ID DESC) AS W1 WHERE W1.WORKER_ID <=5 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+\n",
      "|FIRST_NAME|DEPARTMENT|SALARY|\n",
      "+----------+----------+------+\n",
      "|    Vishal|        HR|300000|\n",
      "|   Amitabh|     Admin|500000|\n",
      "|     Vivek|     Admin|500000|\n",
      "|     Vipul|   Account|200000|\n",
      "+----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-45. Write an SQL query to print the name of employees having the highest salary in each department.\n",
    "spark.sql(\" select FIRST_NAME, DEPARTMENT, SALARY from worker_data where SALARY in (select max(SALARY) as salary from worker_data group by DEPARTMENT) \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|FIRST_NAME|SALARY|\n",
      "+----------+------+\n",
      "|   Amitabh|500000|\n",
      "|     Vivek|500000|\n",
      "|    Vishal|300000|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-46. Write an SQL query to fetch three max salaries from a table.\n",
    "spark.sql(\" select FIRST_NAME, SALARY from worker_data order by SALARY desc limit 3 \").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|FIRST_NAME|SALARY|\n",
      "+----------+------+\n",
      "|    Satish| 75000|\n",
      "|     Subro| 75000|\n",
      "|  Niharika| 80000|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-47. Write an SQL query to fetch three min salaries from a table.\n",
    "spark.sql(\" select FIRST_NAME, SALARY from worker_data order by SALARY asc limit 3 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|FIRST_NAME|SALARY|\n",
      "+----------+------+\n",
      "|   Amitabh|500000|\n",
      "|     Vivek|500000|\n",
      "|    Vishal|300000|\n",
      "|     Vipul|200000|\n",
      "|    Monika|100000|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-48. Write an SQL query to fetch nth max salaries from a table.\n",
    "spark.sql(\" select FIRST_NAME, SALARY from worker_data order by SALARY desc limit 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|DEPARTMENT|sum(SALARY)|\n",
      "+----------+-----------+\n",
      "|        HR|     400000|\n",
      "|     Admin|    1254000|\n",
      "|   Account|     350000|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-49. Write an SQL query to fetch departments along with the total salaries paid for each of them.\n",
    "spark.sql(\" select DEPARTMENT, sum(SALARY) from worker_data group by DEPARTMENT \").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|FIRST_NAME|SALARY|\n",
      "+----------+------+\n",
      "|   Amitabh|500000|\n",
      "|     Vivek|500000|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q-50. Write an SQL query to fetch the names of workers who earn the highest salary.\n",
    "spark.sql(\" select FIRST_NAME, SALARY from worker_data where SALARY=(select max(SALARY) from worker_data) \").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
